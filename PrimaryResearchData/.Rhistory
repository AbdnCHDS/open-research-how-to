)
raw_data <- data.frame(
ID = c(1, 2, 3, 4),
sex = c(0, 1, "Female", "m")
)
raw_data %>%
mutate(sex = tolower(sex)) %>%
left_join(sex_str2num, by = "sex")
sex_str2num <- data.frame(
sex = c(1, 0, "f", "female", "m", "male"),
sex_numeric = c(1, 0, 1, 1, 0, 0)
)
raw_data <- data.frame(
ID = c(1, 2, 3, 4, 5),
sex = c(0, 1, "Female", "m","F")
)
raw_data %>%
mutate(sex = tolower(sex)) %>%
left_join(sex_str2num, by = "sex")
sex_str2num <- data.frame(
sex = c(1, 0, "f", "female", "m", "male"),
sex_numeric = c(1, 0, 1, 1, 0, 0)
)
raw_data <- tibble(
ID = c(1, 2, 3, 4, 5),
sex = c(0, 1, "Female", "m","F")
)
raw_data %>%
mutate(sex = tolower(sex)) %>%
left_join(sex_str2num, by = "sex")
sex_str2num <- data.frame(
sex = c(1, 0, "f", "female", "m", "male"),
sex_numeric = c(1, 0, 1, 1, 0, 0)
)
raw_data <- data.frame(
ID = c(1, 2, 3, 4, 5),
sex = c(0, 1, "Female", "m","F"),
age = c(23,34,15,45,66)
)
raw_data %>%
mutate(sex = tolower(sex)) %>%
left_join(sex_str2num, by = "sex")
library(dplyr)
sex_str2num <- data.frame(
sex = c(1, 0, "f", "female", "m", "male"),
sex_numeric = c(1, 0, 1, 1, 0, 0)
)
raw_data <- data.frame(
ID = c(1, 2, 3, 4, 5),
sex = c(0, 1, "Female", "m","F"),
age = c(23,34,15,45,66)
)
raw_data %>%
mutate(sex = tolower(sex)) %>%
left_join(sex_str2num, by = "sex")
proc_data <- raw_data %>%
mutate(sex = tolower(sex)) %>%
left_join(sex_str2num, by = "sex")
proc_data
raw_data
sex_str2num
list = colnames(proc_data)
for name in list
for (name in list){disp(name)}
for (name in list){print(name)}
raw_data <- data.frame(
ID = c(1, 2, 3, 4, 5),
sex = c(0, 1, "Female", "m","F"),
age = c(23,34,15,45,66)
)
summary(raw_data)
View(raw_data)
is.numeric(raw_data$sex)
is.numeric(raw_data$age)
raw_data <- data.frame(
ID = c(1, 2, 3, 4, 5),
sex = c(0, 1, "Female", "m","F"),
age = c(23,34,15,45,66)
)
is.numeric(raw_data$sex)
is.numeric(raw_data$age)
library(dplyr)
raw_data %>%
is.numeric(sex)
summary(raw_data)
str(raw_data)
str(raw_data)
sex <- raw_data$sex
str(sex)
x <- 3  # Check the "Environment" window!
y <- 6
2+2
library(bookdown)
span <- interval(ymd_hms("2009-01-01 00:00:00"), ymd_hms("2010-02-02 01:01:01"))
library(lubridate)
span <- interval(ymd_hms("2009-01-01 00:00:00"), ymd_hms("2010-02-02 01:01:01"))
as.period(span, units = "years")
age <- as.period(span, units = "years")
install.packages("devtools")
devtools::install_github("rstudio-education/dsbox")
install.packages(gradethis)
install.packages("gradethis")
install.packages("learnr")
devtools::install_github("rstudio-education/dsbox")
install.packages("gradethis")
.libPaths()
install.packages("yaml")
devtools::install_github("rstudio-education/dsbox")
devtools::install_github("rstudio-education/dsbox")
install.packages("backports")
devtools::install_github("rstudio-education/dsbox")
install.packages("digest")
devtools::install_github("rstudio-education/dsbox")
library(nnfor)
library(zoo)
# Create some fake data to test method
# variables
n <- 100 # number of data points
#t <- seq(from=0,to=4*pi,length.out=n+50)
#y1 <- sin(2*t[1:n])
#y2 <- cos(t[5:(4+n)])
#y <- 0.01*runif(n) # add uniform noise
y1 <- runif(n)
#y[8:n] <- y[8:n] + y1[1:(n-7)] + y2[1:(n-7)]
#y[8:n] <-  y1[1:(n-7)] + y2[1:(n-7)]
y <- runif(n)
y[8:n] <-  y1[1:(n-7)]
dates = seq(from=as.Date("2020-01-01"),to=as.Date("2020-12-31"),by='days')
dates <- dates[1:n]
data <- data.frame(dates,y1,y2,y)
Ydata <- subset(data, select = c(dates,y))
Xdata <- subset(data, select = -y)
input_data <- as.ts(read.zoo(Ydata[1:80,]))
exo_data <- as.ts(read.zoo(Xdata[1:80,]))
exo_data_all <- as.ts(read.zoo(Xdata))
fit_model <- mlp(input_data, lags=5:15, xreg=exo_data)
print(fit_model)
data <- data.frame(dates,y1,y)
View(data)
View(data)
Ydata <- subset(data, select = c(dates,y))
Xdata <- subset(data, select = -y)
input_data <- as.ts(read.zoo(Ydata[1:80,]))
exo_data <- as.ts(read.zoo(Xdata[1:80,]))
exo_data_all <- as.ts(read.zoo(Xdata))
fit_model <- mlp(input_data, lags=5:15, xreg=exo_data)
print(fit_model)
View(Xdata)
View(Ydata)
fit_model <- mlp(input_data, lags=5:15, xreg=exo_data)
fit_model <- mlp(input_data, lags=5:10, xreg=exo_data)
library(nnfor)
library(zoo)
# Create some fake data to test method
# variables
n <- 100 # number of data points
#t <- seq(from=0,to=4*pi,length.out=n+50)
#y1 <- sin(2*t[1:n])
#y2 <- cos(t[5:(4+n)])
#y <- 0.01*runif(n) # add uniform noise
y1 <- runif(n)
y2 <- runif(n)
y <- runif(n)
#y[8:n] <- y[8:n] + y1[1:(n-7)] + y2[1:(n-7)]
y[8:n] <-  y1[1:(n-7)] + y2[1:(n-7)]
dates = seq(from=as.Date("2020-01-01"),to=as.Date("2020-12-31"),by='days')
dates <- dates[1:n]
data <- data.frame(dates,y1,y2,y)
View(data)
Ydata <- subset(data, select = c(dates,y))
Xdata <- subset(data, select = -y)
input_data <- as.ts(read.zoo(Ydata[1:80,]))
exo_data <- as.ts(read.zoo(Xdata[1:80,]))
exo_data_all <- as.ts(read.zoo(Xdata))
fit_model <- mlp(input_data, lags=5:15, xreg=exo_data)
print(fit_model)
n <- 100 # number of data points
t <- seq(from=0,to=4*pi,length.out=n+50)
y1 <- sin(2*t[1:n])
y1 <- sin(2*t[1:n]) + 0.01*runif(n)
y2 <- cos(t[5:(4+n)]) + 0.01*runif(n)
y <- 0.01*runif(n) # add uniform noise
y[8:n] <- y[8:n] + y1[1:(n-7)] + y2[1:(n-7)]
dates = seq(from=as.Date("2020-01-01"),to=as.Date("2020-12-31"),by='days')
dates <- dates[1:n]
data <- data.frame(dates,y1,y2,y)
Ydata <- subset(data, select = c(dates,y))
Xdata <- subset(data, select = -y)
input_data <- as.ts(read.zoo(Ydata[1:80,]))
exo_data <- as.ts(read.zoo(Xdata[1:80,]))
exo_data_all <- as.ts(read.zoo(Xdata))
fit_model <- mlp(input_data, lags=5:15, xreg=exo_data)
print(fit_model)
frc.reg <- forecast(fit_model,h=7,xreg=exo_data_all)
plot(frc.reg)
library(readr)
breastfeeding <- read_csv("C:/Users/s04db9/Downloads/breastfeeding.csv",
skip = 8)
View(breastfeeding)
summary(breastfeeding)
knitr::opts_chunk$set(echo = F,eval = T,warning = F,message = F)
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)
library(gridExtra)
library(skimr)
#options( tinytex.verbose = TRUE)
my_skim <- skim_with(base = sfl(n = length))
data<-data.frame(Group=rep(c("A","B","C"),3), age=c(1:9))
data%>%
group_by(Group)%>%
my_skim()%>%
transmute(Variable=skim_variable,Group=Group,n=n,Mean=numeric.mean)%>%
kable(caption='\\label{tab:summary1} Summary statistics of age.',booktabs=T,format = "latex",linesep="",digits=2) %>%
kable_styling(font_size = 11,latex_options = "HOLD_position")
View(data)
View(my_skim)
knitr::opts_chunk$set(echo = F,eval = T,warning = F,message = F)
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)
options( tinytex.verbose = TRUE)
data<-data.frame(Group=rep(c("A","B","C"),3), age=c(1:9))
data%>%
group_by(Group)%>%
kable(caption='\\label{tab:summary1} Summary.',booktabs=T,format = "latex",linesep="",digits=2) %>%
kable_styling(font_size = 11,latex_options = "HOLD_position")
install.packages("xfun")
install.packages("xfun")
knitr::opts_chunk$set(echo = F,eval = T,warning = F,message = F)
library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)
options( tinytex.verbose = TRUE)
data<-data.frame(Group=rep(c("A","B","C"),3), age=c(1:9))
df <- data%>%
group_by(Group)
kable(df)
data<-data.frame(Group=rep(c("A","B","C"),3), age=c(1:9))
#df <- data%>%
#  group_by(Group)
#kable(df)
df <- mtcars %>%
mutate(make_model = row.names(mtcars)) %>%
filter(cyl == 4) %>%
select(make_model, mpg, wt) %>%
mutate(wt = wt*1000) %>%
arrange(make_model)
kable(df)
a<=34
sd
options( tinytex.verbose = TRUE)
require(rms)
library(Hmisc)
try<-data.frame(a=1:10,b=12:21)
latex(describe(try),file = '')
#require(rms)
#library(Hmisc)
try<-data.frame(a=1:10,b=12:21)
latex(describe(try),file = '')
#require(rms)
library(Hmisc)
try<-data.frame(a=1:10,b=12:21)
latex(describe(try),file = '')
options( tinytex.verbose = TRUE)
options( tinytex.verbose = TRUE)
rmarkdown::pandoc_version()
df1 = data.frame(X = sample(5:89, 200, replace = TRUE))
View(df1)
df1 = data.frame(sex = sample(1:2, 200, replace = TRUE),
age = sample(5:89, 200, replace = TRUE),
smoking-per-day = rnorm(n = 200, mean = 12, sd = 5))
df1 = data.frame(sex = sample(1:2, 200, replace = TRUE),
age = sample(5:89, 200, replace = TRUE),
smoking-per-day = rnorm(n = 200, mean = 12, sd = 5))
df1 <- data.frame(ID = c(1, 2, 3, 4, 5),
var1 = c('a', 'b', 'c', 'd', 'e'),
var2 = c(1, 1, 0, 0, 1))
df1 <- data.frame(sex = sample(1:2, 200, replace = TRUE),
age = sample(5:89, 200, replace = TRUE),
smoking-per-day = rnorm(n = 200, mean = 12, sd = 5))
df1 <- data.frame(smoking-per-day = rnorm(n = 200, mean = 12, sd = 5))
df1 <- data.frame(sex = sample(1:2, 200, replace = TRUE),
age = sample(5:89, 200, replace = TRUE),
smoking_per_day = rnorm(n = 200, mean = 12, sd = 5))
View(df1)
View(df1)
df1 <- data.frame(sex = sample(1:2, 200, replace = TRUE),
age = sample(5:89, 200, replace = TRUE),
smoking_per_day = round(rnorm(n = 200, mean = 12, sd = 5)))
View(df1)
table(df1$age,df1$smoking_per_day)
df1 %>%
ggplot() +
geom_point(aes(x = age, y = smoking_per_day))
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
df1 %>%
ggplot() +
geom_point(aes(x = age, y = smoking_per_day))
write_csv(df1, "smoking_data.csv")
library(here)
library(tidyverse)
library(janitor)
library(sf)
library(flexdashboard)
#load data and shapefile
simd_zones <- read_csv(here("data", "SIMD+2020v2+-+datazone+lookup.csv"))
simd_indicators <- read_csv(here("data", "SIMD2020v2_indicators.csv"))
datazone_sf <- st_read(here("data", "sc_dz_11.shp"), quiet = T)
occupations <- read_csv(here("data", "SNS Data Zone 2011 blk", "QS605SC.csv")) %>%
clean_names()
#add variables with all occupations as percentages of total datazone population
occupations <-
occupations %>%
mutate(
across(
a_agriculture_forestry_and_fishing:u_activities_of_extraterritorial_organisations_and_bodies,
~ .x/all_people_aged_16_to_74_in_employment *100,
.names = "perc_{col}"))
#join SIMD files and occupations
simd <-
left_join(simd_indicators, simd_zones, by = c("Data_Zone" = "DZ")) %>%
left_join(., occupations, by = c("Data_Zone" = "x1"))
#remove "%" and "*"
#occupations are charachter fields after joining - why?
simd <-
simd %>%
mutate(across(everything(), ~ str_remove_all(., "%")),
across(everything(), ~ str_remove_all(., "\\*")),
across(Total_population:nocentralheat_rate, ~ as.numeric(.)),
across(SIMD2020v2_Rank:Working_Age_Population, ~ as.numeric(.)),
across(all_people_aged_16_to_74_in_employment:perc_u_activities_of_extraterritorial_organisations_and_bodies, ~ as.numeric(.)))
#calculate population density
datazone_sf <-
datazone_sf %>% mutate(pop_per_km2 = TotPop2011/StdAreaKm2)
#adds population density back to simd file from the shapefile
simd <-
datazone_sf %>%
st_drop_geometry() %>%
select(DataZone, pop_per_km2) %>%
left_join(simd, ., by = c("Data_Zone" = "DataZone"))
# create grampian specific file and score index
grampian_index <-
simd %>%
filter(HBname == "Grampian") %>%
mutate(
perc_essential = perc_c_manufacturing + perc_f_construction + perc_g_wholesale_and_retail_trade_repair_of_motor_vehicles_and_motorcycles + perc_i_accommodation_and_food_service_activities + perc_p_education + perc_q_human_health_and_social_work_activities) %>%
select(Data_Zone, DZname, Council_area, Total_population, SIMD2020v2_Rank, SIMD2020v2_Decile, overcrowded_rate, pop_per_km2, perc_essential)
# grampian_index <-
# grampian_index %>%
#   mutate(scale_overcrowded = overcrowded_rate/max(overcrowded_rate) *10,
#          scale_density = pop_per_km2/max(pop_per_km2) *10,
#          scale_essential = perc_essential/max(perc_essential) *10,
#          sum_scaled_score = scale_overcrowded + scale_density + scale_essential)
grampian_index <-
grampian_index %>%
mutate(percentile_overcrowded = ntile(overcrowded_rate, 100),
percentile_essential = ntile(perc_essential, 100),
percentile_density = ntile(pop_per_km2, 100),
sum_percentile_score = percentile_overcrowded + percentile_essential + percentile_density,
sum_score_decile = ntile(sum_percentile_score, 10))
#select Aberdeen City, Aberdeenshire and Moray's data
#join to make separate shapefiles
aberdeen <-
grampian_index %>%
filter(Council_area == "Aberdeen City")
aberdeen_data_zones <- pull(aberdeen, Data_Zone)
aberdeen_sf <- filter(datazone_sf, DataZone %in% aberdeen_data_zones)
aberdeen_sf <-
left_join(aberdeen_sf, aberdeen, by = c("DataZone" = "Data_Zone"))
aberdeenshire <-
grampian_index %>%
filter(Council_area == "Aberdeenshire")
aberdeenshire_data_zones <- pull(aberdeenshire, Data_Zone)
aberdeenshire_sf <- filter(datazone_sf, DataZone %in% aberdeenshire_data_zones)
aberdeenshire_sf <-
left_join(aberdeenshire_sf, aberdeenshire, by = c("DataZone" = "Data_Zone"))
moray <-
grampian_index %>%
filter(Council_area == "Moray")
moray_data_zones <- pull(moray, Data_Zone)
moray_sf <- filter(datazone_sf, DataZone %in% moray_data_zones)
moray_sf <-
left_join(moray_sf, moray, by = c("DataZone" = "Data_Zone"))
View(grampian_index)
View(moray_sf)
library(nnfor)
library(zoo)
# Create some fake data to test method
# variables
n <- 100 # number of data points
t <- seq(from=0,to=4*pi,length.out=n+50)
y1 <- sin(2*t[1:n]) + 0.01*runif(n)
y2 <- cos(t[5:(4+n)]) + 0.01*runif(n)
y <- 0.01*runif(n) # add uniform noise
y[8:n] <- y[8:n] + y1[1:(n-7)] + y2[1:(n-7)]
dates = seq(from=as.Date("2020-01-01"),to=as.Date("2020-12-31"),by='days')
dates <- dates[1:n]
data <- data.frame(dates,y1,y2,y)
Ydata <- subset(data, select = c(dates,y))
Xdata <- subset(data, select = -y)
input_data <- as.ts(read.zoo(Ydata[1:80,]))
exo_data <- as.ts(read.zoo(Xdata[1:80,]))
exo_data_all <- as.ts(read.zoo(Xdata))
fit_model <- mlp(input_data, lags=5:15, xreg=exo_data)
print(fit_model)
frc.reg <- forecast(fit_model,h=7,xreg=exo_data_all)
plot(frc.reg)
library(readxl)
Fake_Dataset_1_ <- read_excel("C:/Users/s04db9/OneDrive - University of Aberdeen/Teaching/MSc_Projects/Kathleen/Fake Dataset (1).xlsx")
View(Fake_Dataset_1_)
library(tidyverse)
library(dplyr)
head(`Fake.Dataset.(1)`)
library(tsibble)
head(`Fake.Dataset_1_`)
head(`Fake_Dataset_1_`)
head(`Fake_Dataset_1_`$Sending.Practice)
summary(`Fake_Dataset_1_`$Sending.Practice)
head(`Fake_Dataset_1_`$`Sending Practice`)
summary(`Fake_Dataset_1_`$`Sending Practice`)
names(`Fake_Dataset_1_`)
dim(`Fake_Dataset_1_`)
library(tidyverse)
library(finalfit)
library(broom)
library(tsibble)
library(fable)
library(feasts)
library(forecast)
library(MLmetrics)
library(reshape2)
library(nnfor)
library(imputeTS)
table_LoS = read.csv(here::here("data", "average_LoS_by_outcome_cocin.csv"))
library(tidyverse)
who
library(swirl)
install.packages("swirl")
library(swirl)
swirl()
swirl()
5+7
x <- 5+7
x
y <- x-3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z,555,z)
z * 2 + 100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 1000
my_div
install_course_github("swirldev", "R_Programming_E")
swirl()
getwd()
ls()
x <- 9
ls()
dir()
?list.files
args(list.files())
args(list.files)
old.dir <- getwd()
dir.create("testdir")
setwd("testdir")
file.create("mytest.R")
dir()
file.exists("mytest.R")
file.info("mytest.R")
file.rename("mytest.R","mytest2.R")
file.copy("mytest2.R","mytest3.R")
file.path("mytest3.R")
file.path('folder1','folder2')
?dir.create
dir.create(file.path('testdir2','testdir3'))
dir.create(file.path('testdir2','testdir3'), recursive = TRUE)
setwd(old.dir)
swirl()
install_course("Getting and Cleaning Data")
swirl()
sentence <- "Hello Bob"
gsub("Bob","Alice",sentence)
?gsub
sentence <- gsub("Bob","Alice",sentence)
sqrt(4)
sentence <- "I love cars"
gsub("car","bicycle",sentence)
getwd()
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
# 2+2
# R sucks!
R sucks!
2+2
?mean
x <- 5
setwd("C:/Users/s04db9/Code/open-research-how-to/PrimaryResearchData")
